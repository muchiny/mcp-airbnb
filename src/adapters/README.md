# âš¡ Adapters Layer

The **adapters layer** provides concrete implementations of the port traits. This is where all I/O happens â€” HTTP requests to Airbnb (via GraphQL API or HTML scraping) and in-memory caching.

## ğŸ“‚ Structure

```
adapters/
â”œâ”€â”€ graphql/             # ğŸ”— GraphQL API â€” primary data source
â”‚   â”œâ”€â”€ client.rs        #    AirbnbGraphQLClient â€” persisted queries, all 7 methods
â”‚   â””â”€â”€ parsers/         #    JSON â†’ domain type parsers
â”‚       â”œâ”€â”€ search.rs    #    ğŸ” StaysSearch â†’ SearchResult
â”‚       â”œâ”€â”€ detail.rs    #    ğŸ“‹ StaysPdpSections â†’ ListingDetail
â”‚       â”œâ”€â”€ review.rs    #    â­ StaysPdpReviewsQuery â†’ ReviewsPage
â”‚       â””â”€â”€ host.rs      #    ğŸ‘¤ StaysPdpSections â†’ HostProfile
â”œâ”€â”€ scraper/             # ğŸ•·ï¸ HTML scraper â€” fallback data source
â”‚   â”œâ”€â”€ client.rs        #    AirbnbScraper â€” HTTP client, retry, cache-aside
â”‚   â”œâ”€â”€ search_parser.rs #    ğŸ” Search HTML â†’ SearchResult
â”‚   â”œâ”€â”€ detail_parser.rs #    ğŸ“‹ Detail HTML â†’ ListingDetail
â”‚   â”œâ”€â”€ review_parser.rs #    â­ Review HTML â†’ ReviewsPage
â”‚   â”œâ”€â”€ calendar_parser.rs #  ğŸ“… Calendar HTML â†’ PriceCalendar
â”‚   â””â”€â”€ rate_limiter.rs  #    â±ï¸ Token-bucket rate limiter
â”œâ”€â”€ cache/               # ğŸ’¾ In-memory LRU cache
â”‚   â””â”€â”€ memory_cache.rs  #    MemoryCache â€” LRU eviction + TTL
â”œâ”€â”€ composite.rs         # ğŸ”€ CompositeClient â€” GraphQL + Scraper auto-fallback
â”œâ”€â”€ shared.rs            # ğŸ”‘ ApiKeyManager â€” auto-fetched API key with TTL
â””â”€â”€ mod.rs
```

> See [graphql/README.md](graphql/README.md), [scraper/README.md](scraper/README.md), [cache/README.md](cache/README.md) for detailed documentation.

## ğŸ›ï¸ Architecture

```mermaid
flowchart TD
    subgraph Composite["ğŸ”€ CompositeClient"]
        direction TB
        GQL["ğŸ”— AirbnbGraphQLClient<br/>(primary)"]
        Scraper["ğŸ•·ï¸ AirbnbScraper<br/>(fallback)"]
    end

    subgraph Shared["ğŸ”‘ Shared"]
        Keys["ApiKeyManager<br/>Auto-fetched API key"]
    end

    subgraph Cache["ğŸ’¾ Cache"]
        LRU["MemoryCache<br/>LRU + TTL"]
    end

    Composite --> Keys
    GQL --> Keys
    Scraper --> Keys
    GQL --> LRU
    Scraper --> LRU

    GQL -->|"GraphQL API"| AB["ğŸŒ Airbnb"]
    Scraper -->|"HTTP GET"| AB
```

## ğŸ”€ Composite Client

`CompositeClient` orchestrates the dual data source strategy:

1. ğŸ”— **Try GraphQL first** â€” fast, structured JSON responses
2. ğŸ•·ï¸ **Fallback to HTML scraper** â€” if GraphQL fails (rate limit, format change, etc.)
3. ğŸ”„ **Smart merging** â€” for detail and reviews, merges results from both sources

Uses the `with_fallback!` macro for consistent error handling across all methods.

## ğŸ”‘ API Key Manager (`shared.rs`)

- ğŸŒ Fetches `X-Airbnb-Api-Key` from the Airbnb homepage
- ğŸ’¾ Caches the key with configurable TTL (default: 24 hours)
- ğŸ”— Shared between GraphQL and Scraper via `Arc<ApiKeyManager>`
- ğŸ”’ Thread-safe with `RwLock`-based caching

## ğŸ—ï¸ Cache Key Strategy

| Tool | Cache Key Pattern | Default TTL |
|------|-------------------|-------------|
| ğŸ” Search | `search:{location}:{checkin}:{checkout}:{adults}:{cursor}` | 15 min (900s) |
| ğŸ“‹ Detail | `detail:{id}` | 1 hour (3600s) |
| â­ Reviews | `reviews:{id}:{cursor\|"first"}` | 1 hour (3600s) |
| ğŸ“… Calendar | `calendar:{id}:m={months}` | 30 min (1800s) |

GraphQL adapter prefixes keys with `gql:` (e.g., `gql:detail:{id}`), while the scraper uses unprefixed keys.

## ğŸ”„ Parsing Strategy

All HTML parsers follow the same multi-tier extraction strategy:

```mermaid
flowchart TD
    HTML["ğŸ“„ Raw HTML Response"]
    HTML --> ND{"ğŸ” __NEXT_DATA__ exists?"}
    ND -->|Yes| ParseJSON["ğŸ“¦ Parse JSON payload"]
    ND -->|No| DS{"ğŸ” data-deferred-state exists?"}
    ParseJSON --> Extract["ğŸ¯ Extract via known JSON paths"]
    Extract --> Found{"âœ… Data found?"}
    Found -->|Yes| Result["âœ… Return parsed result"]
    Found -->|No| Deep["ğŸ” Recursive deep search"]
    Deep -->|Found| Result
    Deep -->|Not found| DS
    DS -->|Yes| ParseDeferred["ğŸ“¦ Parse deferred state JSON"]
    ParseDeferred --> Extract
    DS -->|No| CSS["ğŸ¨ CSS Selector Fallback"]
    CSS --> CSSParse["ğŸ” Parse via itemprop & data-testid"]
    CSSParse -->|Found| Result
    CSSParse -->|Empty| Error["âŒ Parse Error"]
```
