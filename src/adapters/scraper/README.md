# ğŸ•·ï¸ Web Scraper Adapter

Implements `AirbnbClient` by scraping public Airbnb pages. This adapter serves as the **fallback data source** behind the GraphQL client â€” it fetches HTML pages, extracts structured JSON from embedded scripts, and falls back to CSS selectors when needed.

## ğŸ“‚ Files

| File | Responsibility |
|------|---------------|
| `client.rs` | ğŸ—ï¸ `AirbnbScraper` struct â€” HTTP fetching, retry with exponential backoff, cache-aside pattern |
| `search_parser.rs` | ğŸ” Parses search results page â†’ `SearchResult` |
| `detail_parser.rs` | ğŸ“‹ Parses listing detail page â†’ `ListingDetail` |
| `review_parser.rs` | â­ Parses reviews from listing page â†’ `ReviewsPage` |
| `calendar_parser.rs` | ğŸ“… Parses price calendar from listing page â†’ `PriceCalendar` |
| `rate_limiter.rs` | â±ï¸ Tokio-compatible rate limiter with configurable interval |

## ğŸ”§ `AirbnbScraper`

The main client struct owns:

- **`reqwest::Client`** â€” ğŸŒ HTTP client with cookie jar and custom User-Agent
- **`RateLimiter`** â€” â±ï¸ Throttles requests to respect Airbnb's rate limits
- **`Arc<dyn ListingCache>`** â€” ğŸ’¾ Shared cache reference for the cache-aside pattern
- **`Arc<ApiKeyManager>`** â€” ğŸ”‘ Shared API key manager
- **`ScraperConfig` + `CacheConfig`** â€” âš™ï¸ Runtime configuration

### ğŸ’¾ Cache-Aside Pattern

Every `AirbnbClient` method follows the same flow:

1. ğŸ”‘ Build cache key (e.g., `detail:{id}`)
2. ğŸ” Check cache â€” if hit, deserialize and return
3. â±ï¸ Rate-limit, then fetch HTML via `fetch_html()`
4. ğŸ”§ Parse HTML with the appropriate parser
5. ğŸ’¾ Serialize and store in cache with TTL
6. âœ… Return the parsed result

### ğŸ”„ Retry Logic

`fetch_html()` retries on failure with exponential backoff:

- ğŸ”¢ Up to `max_retries` attempts (default: 2)
- â³ Delay: `attempt * 2` seconds between retries
- â±ï¸ Re-acquires rate limiter token before each retry
- ğŸš« Returns `RateLimited` error on HTTP 429 (no retry)
- ğŸš« Returns `Parse` error on HTTP 404 (no retry)

## ğŸ“Š Parser Architecture

```mermaid
sequenceDiagram
    participant Client as ğŸ•·ï¸ AirbnbScraper
    participant Cache as ğŸ’¾ MemoryCache
    participant RL as â±ï¸ RateLimiter
    participant HTTP as ğŸŒ reqwest::Client
    participant Parser as ğŸ” Parser Module

    Client->>Cache: get(cache_key)
    alt Cache Hit
        Cache-->>Client: cached JSON
        Client->>Client: serde_json::from_str()
        Client-->>Client: Return result
    else Cache Miss
        Client->>RL: wait()
        RL-->>Client: Ready
        Client->>HTTP: GET url
        HTTP-->>Client: HTML response
        Client->>Parser: parse(html, ...)
        Note over Parser: 1ï¸âƒ£ Try __NEXT_DATA__ JSON
        Note over Parser: 2ï¸âƒ£ Try data-deferred-state JSON
        Note over Parser: 3ï¸âƒ£ Fall back to CSS selectors
        Parser-->>Client: Parsed result
        Client->>Cache: set(key, json, TTL)
    end
```

### ğŸ¯ Parsing Tiers

1. **`__NEXT_DATA__`** â€” Airbnb embeds a `<script id="__NEXT_DATA__">` tag containing the full page data as JSON. This is the most reliable source.
2. **`data-deferred-state`** â€” Some pages use `<script>` tags with `data-deferred-state` attributes containing deferred JSON payloads.
3. **ğŸ¨ CSS Selectors** â€” Last resort fallback. Extracts data from HTML elements using `itemprop`, `data-testid`, and other attributes.

## â±ï¸ Rate Limiter

Token-bucket style limiter (`rate_limiter.rs`):

- ğŸ“ Calculates `min_interval` from `rate_limit_per_second` (e.g., 0.5 req/s â†’ 2 second interval)
- ğŸ”’ Tracks last request time via `Mutex<Option<Instant>>`
- ğŸ˜´ Calls `tokio::time::sleep()` when throttled â€” fully async-compatible
- â±ï¸ Applied before every HTTP request, including retries
